{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIEher0OlQ61",
        "outputId": "646021aa-964a-4b61-d5ee-5345a2995b79"
      },
      "outputs": [],
      "source": [
        "#!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "zJ7xNU3NcCwz",
        "outputId": "b33e221c-3287-4505-8379-f35213824cf1"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from copy import deepcopy\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Subset\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk95CyQP6Sfa"
      },
      "source": [
        "## Weights and Bias Login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Amah_vX1lNE-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "wandb: Currently logged in as: fabianfuchs. Use `wandb login --relogin` to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7odmCw657Me2"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ConvNeXtV2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL0UcU1cGeqP"
      },
      "source": [
        "Got source code for the ConvNeXtV2 model from https://github.com/facebookresearch/ConvNeXt-V2/blob/main/models/convnextv2.py and removed drop path and custom weight initialization. Added variable patch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "kA6kljA77MAe"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"LayerNorm that supports two data formats: channels_last (default) or channels_first.\n",
        "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n",
        "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n",
        "    with shape (batch_size, channels, height, width).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
        "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
        "        self.eps = eps\n",
        "        self.data_format = data_format\n",
        "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
        "            raise NotImplementedError\n",
        "        self.normalized_shape = (normalized_shape,)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.data_format == \"channels_last\":\n",
        "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
        "        elif self.data_format == \"channels_first\":\n",
        "            u = x.mean(1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.eps)\n",
        "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
        "            return x\n",
        "\n",
        "\n",
        "class GRN(nn.Module):\n",
        "    \"\"\"GRN (Global Response Normalization) layer\"\"\"\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
        "        self.beta = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        Gx = torch.norm(x, p=2, dim=(1, 2), keepdim=True)\n",
        "        Nx = Gx / (Gx.mean(dim=-1, keepdim=True) + 1e-6)\n",
        "        return self.gamma * (x * Nx) + self.beta + x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"ConvNeXtV2 Block.\"\"\"\n",
        "\n",
        "    def __init__(self, dim, drop_path=0.0):\n",
        "        \"\"\"ConvNeXtV2 Block.\n",
        "\n",
        "        Args:\n",
        "            dim (int): Number of input channels.\n",
        "            drop_path (float): Stochastic depth rate. Default: 0.0\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
        "        self.norm = LayerNorm(dim, eps=1e-6)\n",
        "        self.pwconv1 = nn.Linear(dim, 4 * dim)  # pointwise/1x1 convs, implemented with linear layers\n",
        "        self.act = nn.GELU()\n",
        "        self.grn = GRN(4 * dim)\n",
        "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = x\n",
        "        x = self.dwconv(x)\n",
        "        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n",
        "        x = self.norm(x)\n",
        "        x = self.pwconv1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.grn(x)\n",
        "        x = self.pwconv2(x)\n",
        "        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
        "\n",
        "        return input + x\n",
        "\n",
        "\n",
        "class ConvNeXtV2(nn.Module):\n",
        "    \"\"\"ConvNeXt V2.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_chans=3,\n",
        "        num_classes=1000,\n",
        "        depths=[3, 3, 9, 3],\n",
        "        dims=[96, 192, 384, 768],\n",
        "        drop_path_rate=0.0,\n",
        "        patch_size=1,\n",
        "    ):\n",
        "        \"\"\"ConvNeXt V2.\n",
        "\n",
        "        Args:\n",
        "            in_chans (int): Number of input image channels. Default: 3\n",
        "            num_classes (int): Number of classes for classification head. Default: 1000\n",
        "            depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
        "            dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
        "            drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
        "            head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.depths = depths\n",
        "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
        "        stem = nn.Sequential(\n",
        "            nn.Conv2d(in_chans, dims[0], kernel_size=patch_size, stride=patch_size),\n",
        "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\"),\n",
        "        )\n",
        "        self.downsample_layers.append(stem)\n",
        "        for i in range(3):\n",
        "            downsample_layer = nn.Sequential(\n",
        "                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
        "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
        "            )\n",
        "            self.downsample_layers.append(downsample_layer)\n",
        "\n",
        "        self.stages = nn.ModuleList()  # 4 feature resolution stages, each consisting of multiple residual blocks\n",
        "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
        "        cur = 0\n",
        "        for i in range(4):\n",
        "            stage = nn.Sequential(*[Block(dim=dims[i], drop_path=dp_rates[cur + j]) for j in range(depths[i])])\n",
        "            self.stages.append(stage)\n",
        "            cur += depths[i]\n",
        "\n",
        "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)  # final norm layer\n",
        "        self.head = nn.Linear(dims[-1], num_classes)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        for i in range(4):\n",
        "            x = self.downsample_layers[i](x)\n",
        "            x = self.stages[i](x)\n",
        "        return self.norm(x.mean([-2, -1]))  # global average pooling, (N, C, H, W) -> (N, C)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ConvMixer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "source code from here https://github.com/kentaroy47/vision-transformers-cifar10/blob/main/README.md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(x) + x\n",
        "\n",
        "\n",
        "def ConvMixer(dim, depth, kernel_size=9, patch_size=7, n_classes=1000):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
        "        nn.GELU(),\n",
        "        nn.BatchNorm2d(dim),\n",
        "        *[\n",
        "            nn.Sequential(\n",
        "                Residual(\n",
        "                    nn.Sequential(\n",
        "                        nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"), nn.GELU(), nn.BatchNorm2d(dim)\n",
        "                    )\n",
        "                ),\n",
        "                nn.Conv2d(dim, dim, kernel_size=1),\n",
        "                nn.GELU(),\n",
        "                nn.BatchNorm2d(dim),\n",
        "            )\n",
        "            for i in range(depth)\n",
        "        ],\n",
        "        nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(dim, n_classes),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS1TSvMr6VrH"
      },
      "source": [
        "## Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "QNKuM6tj6Q7q"
      },
      "outputs": [],
      "source": [
        "def get_classes() -> tuple:\n",
        "    \"\"\"Return class labels of CIFAR-10 dataset.\"\"\"\n",
        "    return (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
        "\n",
        "\n",
        "def get_datasets(tasks: int) -> tuple[list[Subset], list[Subset]]:\n",
        "    \"\"\"Split CIFAR-10 dataset into task specific subsets.\n",
        "\n",
        "    Args:\n",
        "        tasks (int): Number of tasks to split the dataset into.\n",
        "\n",
        "    Returns:\n",
        "        tuple[list[Subset], list[Subset]]: Tuple containing two list with the train and test subsets.\n",
        "    \"\"\"\n",
        "    classes = get_classes()\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "    classes_per_task = torch.linspace(0, len(classes), tasks + 1, dtype=torch.int)\n",
        "    trainsets = []\n",
        "    testsets = []\n",
        "    train_targets = torch.tensor(trainset.targets)\n",
        "    test_targets = torch.tensor(testset.targets)\n",
        "    for i in range(len(classes_per_task) - 1):\n",
        "        train_indices = []\n",
        "        test_indices = []\n",
        "        for j in range(classes_per_task[i], classes_per_task[i + 1]):\n",
        "            train_indices.extend((train_targets == j).nonzero(as_tuple=False).flatten().tolist())\n",
        "            test_indices.extend((test_targets == j).nonzero(as_tuple=False).flatten().tolist())\n",
        "        trainsets.append(Subset(trainset, train_indices))\n",
        "        testsets.append(Subset(testset, test_indices))\n",
        "    return trainsets, testsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8E3w1c8iGeqQ"
      },
      "outputs": [],
      "source": [
        "def accuracy(testset: Dataset, model: nn.Module, device: torch.device, batch_size=1) -> float:\n",
        "    testloader = DataLoader(testset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for images, labels in testloader:\n",
        "        # calculate outputs by running images through the network\n",
        "        predictions = model(images.to(device=device))\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(predictions.data, 1)\n",
        "        correct += (predicted == labels.to(device=device)).sum().item()\n",
        "    return 100 * correct / len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nDcsV9XUGeqR"
      },
      "outputs": [],
      "source": [
        "def average_accuracy(\n",
        "    testsets: list[Dataset],\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    return_intermediate: bool = False,  # noqa: FBT001, FBT002\n",
        ") -> float | tuple[float, list[float]]:\n",
        "    average_accuracy = 0\n",
        "    average_accuracies = []\n",
        "    for i in range(len(testsets)):\n",
        "        task_accuracy = accuracy(testset=testsets[i], model=model, device=device)\n",
        "        average_accuracy += task_accuracy\n",
        "        average_accuracies.append(task_accuracy)\n",
        "    if return_intermediate:\n",
        "        return average_accuracy / len(testsets), average_accuracies\n",
        "    return average_accuracy / len(testsets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forgetting_measure(average_accuracies_per_training_per_task: list[list[float]], current_task: int) -> float:\n",
        "    forgetting_measure = 0\n",
        "    for j in range(current_task):  # exclude current task\n",
        "        f = 0\n",
        "        for i in range(j, current_task):  # exclude current task\n",
        "            f_ = (\n",
        "                average_accuracies_per_training_per_task[i][j]\n",
        "                - average_accuracies_per_training_per_task[current_task][j]\n",
        "            )\n",
        "            if f_ > f:\n",
        "                f = f_\n",
        "        forgetting_measure += f\n",
        "    return forgetting_measure / current_task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.66666666666667"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_accuracies_per_training_per_task = [[100], [50, 100], [25, 50, 100], [25, 25, 50, 100]]\n",
        "forgetting_measure(average_accuracies_per_training_per_task=average_accuracies_per_training_per_task, current_task=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### train loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IbR9W9Tw7AVI"
      },
      "outputs": [],
      "source": [
        "def train_on_task(\n",
        "    trainset: Dataset,\n",
        "    testset: Dataset,\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        "):\n",
        "    # create dataloaders\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    # move model to device\n",
        "    model.to(device=device)\n",
        "\n",
        "    if criterion is None:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    if scheduler is None:\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer,\n",
        "            max_lr=lr,\n",
        "            steps_per_epoch=len(trainloader),\n",
        "            epochs=epochs,\n",
        "        )\n",
        "\n",
        "    # training\n",
        "    for epoch in range(epochs):\n",
        "        # train one epoch\n",
        "        with tqdm(total=len(trainset), unit=\"images\") as progress_bar:\n",
        "            model.train()\n",
        "            for i, (images, labels) in enumerate(trainloader):\n",
        "                progress_bar.set_description(f\"Epoch {epoch+1} Batch {i}\")\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                prediction = model(images.to(device=device))\n",
        "                # calc loss\n",
        "                loss = criterion(prediction, labels.to(device=device))\n",
        "                # backward\n",
        "                loss.backward()\n",
        "                # optimizer\n",
        "                optimizer.step()\n",
        "                # scheduler\n",
        "                scheduler.step()\n",
        "                progress_bar.set_postfix(loss=loss.item())\n",
        "                progress_bar.update(labels.shape[0])\n",
        "                wandb.log({\"loss\": loss})\n",
        "                wandb.log({\"lr\": scheduler.get_last_lr()[0]})\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model{epoch}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "        # eval\n",
        "        test_accucracy = accuracy(testset=testset, model=model, device=device, batch_size=batch_size)\n",
        "        wandb.log({\"test_accucracy\": test_accucracy})\n",
        "\n",
        "    # save final model\n",
        "    path = Path(wandb.run.dir).joinpath(\"model.pth\")\n",
        "    torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### concurrent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_tasks_concurrently(  # noqa: PLR0913\n",
        "    model_dict: dict,\n",
        "    device: torch.device,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    weight_decay: float,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        ") -> None:\n",
        "    # build model\n",
        "    constructor = model_dict.pop(\"constructor\")\n",
        "    model_name = model_dict.pop(\"name\")\n",
        "    model = constructor(**model_dict)\n",
        "    # create optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    # setup logging\n",
        "    project_name = \"continual_learning\"\n",
        "    run_name = f\"{datetime.now(tz=timezone.utc).strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "    config = {\n",
        "        \"training_method\": \"concurrently\",\n",
        "        \"model_name\": model_name,\n",
        "        \"dataset\": \"CIFAR-10\",\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"lr\": lr,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "    }\n",
        "    config.update(model_dict)\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    # get datasets\n",
        "    trainsets, testsets = get_datasets(tasks=1)\n",
        "\n",
        "    train_on_task(\n",
        "        trainset=trainsets[0],\n",
        "        testset=testsets[0],\n",
        "        model=model,\n",
        "        device=device,\n",
        "        optimizer=optimizer,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        lr=lr,\n",
        "        criterion=criterion,\n",
        "        scheduler=scheduler,\n",
        "    )\n",
        "    # finish logging run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### sequentially\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gQIXFn8FGeqR"
      },
      "outputs": [],
      "source": [
        "def train_tasks_sequentially(  # noqa: PLR0913\n",
        "    model_dict: dict,\n",
        "    device: torch.device,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    tasks: int,\n",
        "    lr: float,\n",
        "    weight_decay: float,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        ") -> None:\n",
        "    # build model\n",
        "    constructor = model_dict.pop(\"constructor\")\n",
        "    model_name = model_dict.pop(\"name\")\n",
        "    model = constructor(**model_dict)\n",
        "    # create optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    # setup logging\n",
        "    project_name = \"continual_learning\"\n",
        "    run_name = f\"{datetime.now(tz=timezone.utc).strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "    config = {\n",
        "        \"training_method\": \"sequentially\",\n",
        "        \"model_name\": model_name,\n",
        "        \"dataset\": \"CIFAR-10\",\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"tasks\": tasks,\n",
        "        \"lr\": lr,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "    }\n",
        "    config.update(model_dict)\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    # get datasets\n",
        "    trainsets, testsets = get_datasets(tasks=tasks)\n",
        "\n",
        "    avg_accs_per_task = []\n",
        "    for k in range(tasks):\n",
        "        # train model on task\n",
        "        train_on_task(\n",
        "            trainset=trainsets[k],\n",
        "            testset=testsets[k],\n",
        "            model=model,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "        )\n",
        "        # evaluate model\n",
        "        avg_acc, avg_accs = average_accuracy(\n",
        "            testsets=testsets[: k + 1],  # include current task\n",
        "            model=model,\n",
        "            device=device,\n",
        "            return_intermediate=True,\n",
        "        )\n",
        "        avg_accs_per_task.append(avg_accs)\n",
        "        wandb.log({\"accuracy_on_current_task_only\": avg_accs[-1]})\n",
        "        wandb.log({\"average_accuracy\": avg_acc})\n",
        "\n",
        "        # calculate forgetting measure as defined here https://arxiv.org/pdf/2302.00487.pdf\n",
        "        if k > 0:  # forgetting measure only makes sense, if we already trained on prior task\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"forgetting_measure\": forgetting_measure(\n",
        "                        average_accuracies_per_training_per_task=avg_accs_per_task,\n",
        "                        current_task=k,\n",
        "                    ),\n",
        "                },\n",
        "            )\n",
        "\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model_task{k}_of{tasks}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "    # finish logging run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqsnE1JcGeqS"
      },
      "source": [
        "check accuracy_on_current_task_only\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### rehearsal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_tasks_sequentially_rehearsal(  # noqa: PLR0913\n",
        "    model_dict: dict,\n",
        "    device: torch.device,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    tasks: int,\n",
        "    lr: float,\n",
        "    weight_decay: float,\n",
        "    memory_size_per_task: int,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        ") -> None:\n",
        "    # build model\n",
        "    constructor = model_dict.pop(\"constructor\")\n",
        "    model_name = model_dict.pop(\"name\")\n",
        "    model = constructor(**model_dict)\n",
        "    # create optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    # setup logging\n",
        "    project_name = \"continual_learning\"\n",
        "    run_name = f\"{datetime.now(tz=timezone.utc).strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "    config = {\n",
        "        \"training_method\": \"sequentially with rehearsal\",\n",
        "        \"model_name\": model_name,\n",
        "        \"dataset\": \"CIFAR-10\",\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"tasks\": tasks,\n",
        "        \"lr\": lr,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"memory_size_per_task\": memory_size_per_task,\n",
        "        \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "    }\n",
        "    config.update(model_dict)\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    # get datasets\n",
        "    trainsets, testsets = get_datasets(tasks=tasks)\n",
        "\n",
        "    avg_accs_per_task = []\n",
        "    memories = []\n",
        "    for k in range(tasks):\n",
        "        # train model on task\n",
        "        train_on_task(\n",
        "            trainset=ConcatDataset([trainsets[k], *memories]),\n",
        "            testset=testsets[k],\n",
        "            model=model,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "        )\n",
        "        # evaluate model\n",
        "        avg_acc, avg_accs = average_accuracy(\n",
        "            testsets=testsets[: k + 1],  # include current task\n",
        "            model=model,\n",
        "            device=device,\n",
        "            return_intermediate=True,\n",
        "        )\n",
        "        avg_accs_per_task.append(avg_accs)\n",
        "        wandb.log({\"accuracy_on_current_task_only\": avg_accs[-1]})\n",
        "        wandb.log({\"average_accuracy\": avg_acc})\n",
        "\n",
        "        # calculate forgetting measure as defined here https://arxiv.org/pdf/2302.00487.pdf\n",
        "        if k > 0:  # forgetting measure only makes sense, if we already trained on prior task\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"forgetting_measure\": forgetting_measure(\n",
        "                        average_accuracies_per_training_per_task=avg_accs_per_task,\n",
        "                        current_task=k,\n",
        "                    ),\n",
        "                },\n",
        "            )\n",
        "\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model_task{k}_of{tasks}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "        # add come images and labels from current task to memory\n",
        "        random_indices = torch.randint(low=0, high=len(trainsets[k - 1]), size=(memory_size_per_task,))\n",
        "        memory_task = Subset(trainsets[k], random_indices)\n",
        "        memories.append(memory_task)\n",
        "\n",
        "    # finish logging run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### elastic weight consolidation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_fisher_optimal_parameters(\n",
        "    trainset: Subset,\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    batch_size: int,\n",
        "    current_task: int,\n",
        "    fisher_dict: dict,\n",
        "    optpar_dict: dict,\n",
        "    samples_for_fisher_approximation: int,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # get subset from trainset\n",
        "    indices = torch.randint(low=0, high=len(trainset.indices), size=(samples_for_fisher_approximation))\n",
        "    dataset = Subset(trainset.dataset, trainset.indices[indices])\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "    # accumulating gradients\n",
        "    for images, labels in dataloader:\n",
        "        # forward\n",
        "        prediction = model(images.to(device=device))\n",
        "        # calc loss\n",
        "        loss = criterion(prediction, labels.to(device=device))\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "    # gradients accumulated can be used to calculate fisher\n",
        "    for name, param in model.named_parameters():\n",
        "        optpar_dict[current_task][name] = param.data.clone()\n",
        "        fisher_dict[current_task][name] = param.grad.data.clone().pow(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_on_task_with_elastic_weight_loss(\n",
        "    trainset: Subset,\n",
        "    testset: Subset,\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    fisher_dict: dict,\n",
        "    optpar_dict: dict,\n",
        "    ewc_lambda: float,\n",
        "    current_task: int,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        "):\n",
        "    # create dataloaders\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    # move model to device\n",
        "    model.to(device=device)\n",
        "\n",
        "    if criterion is None:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    if scheduler is None:\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer,\n",
        "            max_lr=lr,\n",
        "            steps_per_epoch=len(trainloader),\n",
        "            epochs=epochs,\n",
        "        )\n",
        "\n",
        "    # training\n",
        "    for epoch in range(epochs):\n",
        "        # train one epoch\n",
        "        with tqdm(total=len(trainset), unit=\"images\") as progress_bar:\n",
        "            model.train()\n",
        "            for i, (images, labels) in enumerate(trainloader):\n",
        "                progress_bar.set_description(f\"Epoch {epoch+1} Batch {i}\")\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                prediction = model(images.to(device=device))\n",
        "                # calc loss\n",
        "                loss = criterion(prediction, labels.to(device=device))\n",
        "\n",
        "                # add elastic weight loss\n",
        "                for task in range(current_task):\n",
        "                    for name, param in model.named_parameters():\n",
        "                        fisher = fisher_dict[task][name]\n",
        "                        optpar = optpar_dict[task][name]\n",
        "                        loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n",
        "\n",
        "                # backward\n",
        "                loss.backward()\n",
        "                # optimizer\n",
        "                optimizer.step()\n",
        "                # scheduler\n",
        "                scheduler.step()\n",
        "                progress_bar.set_postfix(loss=loss.item())\n",
        "                progress_bar.update(labels.shape[0])\n",
        "                wandb.log({\"loss\": loss})\n",
        "                wandb.log({\"lr\": scheduler.get_last_lr()[0]})\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model{epoch}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "        # eval\n",
        "        test_accucracy = accuracy(testset=testset, model=model, device=device, batch_size=batch_size)\n",
        "        wandb.log({\"test_accucracy\": test_accucracy})\n",
        "\n",
        "    # save final model\n",
        "    path = Path(wandb.run.dir).joinpath(\"model.pth\")\n",
        "    torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_tasks_sequentially_elastic_weight_consolidation(  # noqa: PLR0913\n",
        "    model_dict: dict,\n",
        "    device: torch.device,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    tasks: int,\n",
        "    lr: float,\n",
        "    weight_decay: float,\n",
        "    ewc_lambda: float,\n",
        "    samples_for_fisher_approximation: int,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        ") -> None:\n",
        "    # build model\n",
        "    constructor = model_dict.pop(\"constructor\")\n",
        "    model_name = model_dict.pop(\"name\")\n",
        "    model = constructor(**model_dict)\n",
        "    # create optimizer\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    # setup logging\n",
        "    project_name = \"continual_learning\"\n",
        "    run_name = f\"{datetime.now(tz=timezone.utc).strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "    config = {\n",
        "        \"training_method\": \"sequentially with elastic weight consolidation\",\n",
        "        \"model_name\": model_name,\n",
        "        \"dataset\": \"CIFAR-10\",\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"tasks\": tasks,\n",
        "        \"lr\": lr,\n",
        "        \"weight_decay\": weight_decay,\n",
        "        \"ewc_lambda\": ewc_lambda,\n",
        "        \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "    }\n",
        "    config.update(model_dict)\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    # get datasets\n",
        "    trainsets, testsets = get_datasets(tasks=tasks)\n",
        "\n",
        "    avg_accs_per_task = []\n",
        "    fisher_dict = {}\n",
        "    optpar_dict = {}\n",
        "    for k in range(tasks):\n",
        "        train_on_task_with_elastic_weight_loss(\n",
        "            trainset=trainsets[k],\n",
        "            testset=testsets[k],\n",
        "            model=model,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            fisher_dict=fisher_dict,\n",
        "            optpar_dict=optpar_dict,\n",
        "            ewc_lambda=ewc_lambda,\n",
        "            current_task=k,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "        )\n",
        "        # evaluate model\n",
        "        avg_acc, avg_accs = average_accuracy(\n",
        "            testsets=testsets[: k + 1],  # include current task\n",
        "            model=model,\n",
        "            device=device,\n",
        "            return_intermediate=True,\n",
        "        )\n",
        "        avg_accs_per_task.append(avg_accs)\n",
        "        wandb.log({\"accuracy_on_current_task_only\": avg_accs[-1]})\n",
        "        wandb.log({\"average_accuracy\": avg_acc})\n",
        "\n",
        "        # calculate forgetting measure as defined here https://arxiv.org/pdf/2302.00487.pdf\n",
        "        if k > 0:  # forgetting measure only makes sense, if we already trained on prior task\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"forgetting_measure\": forgetting_measure(\n",
        "                        average_accuracies_per_training_per_task=avg_accs_per_task,\n",
        "                        current_task=k,\n",
        "                    ),\n",
        "                },\n",
        "            )\n",
        "\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model_task{k}_of{tasks}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "        # gradients accumulated can be used to calculate fisher\n",
        "        calculate_fisher_optimal_parameters(\n",
        "            trainset=trainsets[k],\n",
        "            model=model,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            batch_size=batch_size,\n",
        "            current_task=k,\n",
        "            fisher_dict=fisher_dict,\n",
        "            optpar_dict=optpar_dict,\n",
        "            samples_for_fisher_approximation=samples_for_fisher_approximation,\n",
        "        )\n",
        "\n",
        "    # finish logging run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UILvQs6gGeqS"
      },
      "outputs": [],
      "source": [
        "def load_weights_from_wandb(model: nn.Module, run_name: str) -> nn.Module:\n",
        "    best_model = wandb.restore(\n",
        "        \"model.pth\",\n",
        "        run_path=f\"fabianfuchs/continual_learning/{run_name}\",\n",
        "        root=Path.cwd().joinpath(\"checkpoints\"),\n",
        "        replace=True,\n",
        "    )\n",
        "\n",
        "    # use the \"name\" attribute of the returned object if your framework expects a filename, e.g. as in Keras\n",
        "    model.load_state_dict(torch.load(best_model.name))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIt_EXa1GeqS"
      },
      "source": [
        "## Standard Setting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3psLpC6hGeqS"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "batch_size = 64\n",
        "lr = 0.01\n",
        "momentum = 0.9\n",
        "weight_decay = 0.01\n",
        "device = torch.device(\"cuda:0\")\n",
        "tasks = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convnext_minimal = {\n",
        "#     \"constructor\": ConvNeXtV2,\n",
        "#     \"name\": \"ConvNeXtV2\",\n",
        "#     \"in_chans\": 3,\n",
        "#     \"num_classes\": 10,\n",
        "#     \"depths\": [2, 2, 2, 2],\n",
        "#     \"dims\": [128, 128, 128, 128],\n",
        "#     \"patch_size\": 1,\n",
        "# }\n",
        "# models.append(convnext_minimal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kmRL4K2LGeqS"
      },
      "outputs": [],
      "source": [
        "# convnext_atto = {\n",
        "#     \"constructor\": ConvNeXtV2,\n",
        "#     \"name\": \"ConvNeXtV2\",\n",
        "#     \"in_chans\": 3,\n",
        "#     \"num_classes\": 10,\n",
        "#     \"depths\": [2, 2, 6, 2],\n",
        "#     \"dims\": [40, 80, 160, 320],\n",
        "#     \"patch_size\": 1,\n",
        "# }\n",
        "# models.append(convnext_atto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zX3B6pscGeqT"
      },
      "outputs": [],
      "source": [
        "# convnext_tiny = {\n",
        "#     \"constructor\": ConvNeXtV2,\n",
        "#     \"name\": \"ConvNeXtV2\",\n",
        "#     \"in_chans\": 3,\n",
        "#     \"num_classes\": 10,\n",
        "#     \"depths\": [3, 3, 9, 3],\n",
        "#     \"dims\": [96, 192, 384, 768],\n",
        "#     \"patch_size\": 1,\n",
        "# }\n",
        "# models.append(convnext_tiny)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9OZ7CY4EGeqT"
      },
      "outputs": [],
      "source": [
        "# convnext_base = {\n",
        "#     \"constructor\": ConvNeXtV2,\n",
        "#     \"name\": \"ConvNeXtV2\",\n",
        "#     \"in_chans\": 3,\n",
        "#     \"num_classes\": 10,\n",
        "#     \"depths\": [3, 3, 27, 3],\n",
        "#     \"dims\": [128, 256, 512, 1024],\n",
        "#     \"patch_size\": 1,\n",
        "# }\n",
        "# models.append(convnext_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_mixer_minimal = {\n",
        "    \"constructor\": ConvMixer,\n",
        "    \"name\": \"ConvMixer\",\n",
        "    \"dim\": 128,\n",
        "    \"depth\": 4,\n",
        "    \"kernel_size\": 7,\n",
        "    \"patch_size\": 1,\n",
        "    \"n_classes\": 10,\n",
        "}\n",
        "models.append(conv_mixer_minimal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conv_mixer_atto = {\n",
        "#     \"constructor\": ConvMixer,\n",
        "#     \"name\": \"ConvMixer\",\n",
        "#     \"dim\": 128,\n",
        "#     \"depth\": 8,\n",
        "#     \"kernel_size\": 7,\n",
        "#     \"patch_size\": 1,\n",
        "#     \"n_classes\": 10,\n",
        "# }\n",
        "# models.append(conv_mixer_atto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conv_mixer_tiny = {\n",
        "#     \"constructor\": ConvMixer,\n",
        "#     \"name\": \"ConvMixer\",\n",
        "#     \"dim\": 256,\n",
        "#     \"depth\": 8,\n",
        "#     \"kernel_size\": 7,\n",
        "#     \"patch_size\": 1,\n",
        "#     \"n_classes\": 10,\n",
        "# }\n",
        "# models.append(conv_mixer_tiny)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rHEyR98AGeqT"
      },
      "outputs": [],
      "source": [
        "# for model in models:\n",
        "#     train_tasks_concurrently(\n",
        "#         model_dict=model,\n",
        "#         device=device,\n",
        "#         epochs=epochs,\n",
        "#         batch_size=batch_size,\n",
        "#         lr=lr,\n",
        "#         weight_decay=weight_decay,\n",
        "#     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R59sQDCoGeqT"
      },
      "source": [
        "## Sequential without modifications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iwBNBJFzGeqT"
      },
      "outputs": [],
      "source": [
        "tasks = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0JqT_GCKNG3T"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "wandb version 0.16.6 is available!  To upgrade, please run:\n",
              " $ pip install wandb --upgrade"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>d:\\Users\\f.fuchs\\Git\\continual-learning\\wandb\\run-20240407_105518-f8yhw0dv</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fabianfuchs/continual_learning/runs/f8yhw0dv/workspace' target=\"_blank\">2024_04_07_08_55_18</a></strong> to <a href='https://wandb.ai/fabianfuchs/continual_learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/fabianfuchs/continual_learning' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/fabianfuchs/continual_learning/runs/f8yhw0dv/workspace' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning/runs/f8yhw0dv/workspace</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 156: 100%|| 10000/10000 [00:25<00:00, 399.98images/s, loss=1.63] \n",
            "Epoch 2 Batch 156: 100%|| 10000/10000 [00:20<00:00, 490.73images/s, loss=0.277]\n",
            "Epoch 3 Batch 156: 100%|| 10000/10000 [00:26<00:00, 381.29images/s, loss=0.619] \n",
            "Epoch 4 Batch 156: 100%|| 10000/10000 [00:24<00:00, 409.37images/s, loss=0.372] \n",
            "Epoch 5 Batch 156: 100%|| 10000/10000 [00:24<00:00, 411.30images/s, loss=0.268] \n",
            "Epoch 6 Batch 156: 100%|| 10000/10000 [00:24<00:00, 405.78images/s, loss=0.0778]\n",
            "Epoch 7 Batch 156: 100%|| 10000/10000 [00:24<00:00, 410.48images/s, loss=0.0924]\n",
            "Epoch 8 Batch 156: 100%|| 10000/10000 [00:23<00:00, 427.65images/s, loss=0.0751] \n",
            "Epoch 9 Batch 156: 100%|| 10000/10000 [00:24<00:00, 400.50images/s, loss=0.00683]\n",
            "Epoch 10 Batch 156: 100%|| 10000/10000 [00:24<00:00, 414.18images/s, loss=0.0864] \n",
            "Epoch 11 Batch 156: 100%|| 10000/10000 [00:24<00:00, 401.13images/s, loss=0.0194] \n",
            "Epoch 12 Batch 156: 100%|| 10000/10000 [00:23<00:00, 420.77images/s, loss=3.3e-5] \n",
            "Epoch 13 Batch 156: 100%|| 10000/10000 [00:25<00:00, 395.25images/s, loss=0.14]    \n",
            "Epoch 14 Batch 156: 100%|| 10000/10000 [00:23<00:00, 433.93images/s, loss=0.000433] \n",
            "Epoch 15 Batch 156: 100%|| 10000/10000 [00:21<00:00, 456.78images/s, loss=6.99e-5] \n",
            "Epoch 16 Batch 156: 100%|| 10000/10000 [00:23<00:00, 418.07images/s, loss=0.000121]\n",
            "Epoch 17 Batch 156: 100%|| 10000/10000 [00:23<00:00, 420.96images/s, loss=0.166]   \n",
            "Epoch 18 Batch 156: 100%|| 10000/10000 [00:23<00:00, 429.53images/s, loss=0.0166]  \n",
            "Epoch 19 Batch 156: 100%|| 10000/10000 [00:21<00:00, 467.34images/s, loss=0.000131]\n",
            "Epoch 20 Batch 156: 100%|| 10000/10000 [00:22<00:00, 446.19images/s, loss=0.181]   \n",
            "Epoch 1 Batch 156: 100%|| 10000/10000 [00:25<00:00, 398.16images/s, loss=0.678]\n",
            "Epoch 2 Batch 156: 100%|| 10000/10000 [00:23<00:00, 431.01images/s, loss=0.274] \n",
            "Epoch 3 Batch 156: 100%|| 10000/10000 [00:23<00:00, 432.87images/s, loss=0.211]\n",
            "Epoch 4 Batch 156: 100%|| 10000/10000 [00:23<00:00, 423.34images/s, loss=0.353]\n",
            "Epoch 5 Batch 156: 100%|| 10000/10000 [00:23<00:00, 430.59images/s, loss=0.267] \n",
            "Epoch 6 Batch 156: 100%|| 10000/10000 [00:22<00:00, 441.91images/s, loss=0.104] \n",
            "Epoch 7 Batch 156: 100%|| 10000/10000 [00:22<00:00, 435.16images/s, loss=0.334] \n",
            "Epoch 8 Batch 156: 100%|| 10000/10000 [00:22<00:00, 443.23images/s, loss=0.178] \n",
            "Epoch 9 Batch 156: 100%|| 10000/10000 [00:24<00:00, 406.08images/s, loss=0.074] \n",
            "Epoch 10 Batch 156: 100%|| 10000/10000 [00:22<00:00, 448.50images/s, loss=0.412] \n",
            "Epoch 11 Batch 156: 100%|| 10000/10000 [00:24<00:00, 406.82images/s, loss=0.497] \n",
            "Epoch 12 Batch 156: 100%|| 10000/10000 [00:24<00:00, 407.11images/s, loss=0.107] \n",
            "Epoch 13 Batch 156: 100%|| 10000/10000 [00:24<00:00, 412.49images/s, loss=0.0026] \n",
            "Epoch 14 Batch 156: 100%|| 10000/10000 [00:24<00:00, 410.55images/s, loss=0.173]  \n",
            "Epoch 15 Batch 156: 100%|| 10000/10000 [00:22<00:00, 443.13images/s, loss=0.341]   \n",
            "Epoch 16 Batch 156: 100%|| 10000/10000 [00:25<00:00, 393.76images/s, loss=0.00166] \n",
            "Epoch 17 Batch 156: 100%|| 10000/10000 [00:24<00:00, 405.20images/s, loss=0.648]   \n",
            "Epoch 18 Batch 156: 100%|| 10000/10000 [00:23<00:00, 422.88images/s, loss=0.00715] \n",
            "Epoch 19 Batch 156: 100%|| 10000/10000 [00:23<00:00, 428.54images/s, loss=0.000407]\n",
            "Epoch 20 Batch 156: 100%|| 10000/10000 [00:24<00:00, 409.72images/s, loss=0.00144] \n",
            "Epoch 1 Batch 156: 100%|| 10000/10000 [00:23<00:00, 423.03images/s, loss=0.313]\n",
            "Epoch 2 Batch 156: 100%|| 10000/10000 [00:24<00:00, 415.37images/s, loss=0.41] \n",
            "Epoch 3 Batch 156: 100%|| 10000/10000 [00:24<00:00, 413.73images/s, loss=0.153] \n",
            "Epoch 4 Batch 156: 100%|| 10000/10000 [00:24<00:00, 413.95images/s, loss=0.107] \n",
            "Epoch 5 Batch 156: 100%|| 10000/10000 [00:23<00:00, 427.10images/s, loss=0.168] \n",
            "Epoch 6 Batch 156: 100%|| 10000/10000 [00:24<00:00, 404.43images/s, loss=0.0607] \n",
            "Epoch 7 Batch 156: 100%|| 10000/10000 [00:24<00:00, 412.41images/s, loss=0.503] \n",
            "Epoch 8 Batch 156: 100%|| 10000/10000 [00:22<00:00, 436.45images/s, loss=0.122] \n",
            "Epoch 9 Batch 156: 100%|| 10000/10000 [00:24<00:00, 414.52images/s, loss=0.00954]\n",
            "Epoch 10 Batch 156: 100%|| 10000/10000 [00:23<00:00, 426.59images/s, loss=0.69]  \n",
            "Epoch 11 Batch 156: 100%|| 10000/10000 [00:24<00:00, 401.84images/s, loss=0.17]  \n",
            "Epoch 12 Batch 156: 100%|| 10000/10000 [00:23<00:00, 430.50images/s, loss=0.0759] \n",
            "Epoch 13 Batch 156: 100%|| 10000/10000 [00:25<00:00, 399.01images/s, loss=0.00693] \n",
            "Epoch 14 Batch 156: 100%|| 10000/10000 [00:22<00:00, 437.53images/s, loss=0.011]   \n",
            "Epoch 15 Batch 156: 100%|| 10000/10000 [00:24<00:00, 404.87images/s, loss=0.0016]  \n",
            "Epoch 16 Batch 156: 100%|| 10000/10000 [00:24<00:00, 411.57images/s, loss=0.00163] \n",
            "Epoch 17 Batch 156: 100%|| 10000/10000 [00:24<00:00, 410.37images/s, loss=0.0186]  \n",
            "Epoch 18 Batch 156: 100%|| 10000/10000 [00:24<00:00, 410.18images/s, loss=0.346]   \n",
            "Epoch 19 Batch 156: 100%|| 10000/10000 [00:23<00:00, 433.36images/s, loss=0.0172]  \n",
            "Epoch 20 Batch 156: 100%|| 10000/10000 [00:23<00:00, 428.32images/s, loss=0.000723] \n",
            "Epoch 1 Batch 156: 100%|| 10000/10000 [00:24<00:00, 410.39images/s, loss=0.713]\n",
            "Epoch 2 Batch 156: 100%|| 10000/10000 [00:24<00:00, 406.08images/s, loss=0.057] \n",
            "Epoch 3 Batch 156: 100%|| 10000/10000 [00:25<00:00, 398.79images/s, loss=0.029] \n",
            "Epoch 4 Batch 156: 100%|| 10000/10000 [00:24<00:00, 414.66images/s, loss=0.359] \n",
            "Epoch 5 Batch 156: 100%|| 10000/10000 [00:23<00:00, 430.34images/s, loss=0.0164] \n",
            "Epoch 6 Batch 156: 100%|| 10000/10000 [00:24<00:00, 412.90images/s, loss=0.0621]\n",
            "Epoch 7 Batch 156: 100%|| 10000/10000 [00:21<00:00, 460.52images/s, loss=0.0339] \n",
            "Epoch 8 Batch 156: 100%|| 10000/10000 [00:24<00:00, 415.34images/s, loss=0.000617]\n",
            "Epoch 9 Batch 156: 100%|| 10000/10000 [00:25<00:00, 399.92images/s, loss=0.382]  \n",
            "Epoch 10 Batch 156: 100%|| 10000/10000 [00:24<00:00, 401.01images/s, loss=0.00342] \n",
            "Epoch 11 Batch 156: 100%|| 10000/10000 [00:25<00:00, 390.64images/s, loss=0.0401]  \n",
            "Epoch 12 Batch 156: 100%|| 10000/10000 [00:24<00:00, 401.14images/s, loss=0.0161]  \n",
            "Epoch 13 Batch 156: 100%|| 10000/10000 [00:22<00:00, 436.15images/s, loss=0.00316] \n",
            "Epoch 14 Batch 156: 100%|| 10000/10000 [00:24<00:00, 412.46images/s, loss=0.0105]  \n",
            "Epoch 15 Batch 156: 100%|| 10000/10000 [00:22<00:00, 437.15images/s, loss=0.00154] \n",
            "Epoch 16 Batch 156: 100%|| 10000/10000 [00:24<00:00, 406.77images/s, loss=0.000271]\n",
            "Epoch 17 Batch 156: 100%|| 10000/10000 [00:24<00:00, 406.50images/s, loss=0.000783]\n",
            "Epoch 18 Batch 156: 100%|| 10000/10000 [00:23<00:00, 418.82images/s, loss=6.93e-5] \n",
            "Epoch 19 Batch 156: 100%|| 10000/10000 [00:25<00:00, 391.86images/s, loss=0.000152]\n",
            "Epoch 20 Batch 156: 100%|| 10000/10000 [00:24<00:00, 403.79images/s, loss=6.48e-5] \n",
            "Epoch 1 Batch 156: 100%|| 10000/10000 [00:22<00:00, 440.03images/s, loss=0.163]\n",
            "Epoch 2 Batch 156: 100%|| 10000/10000 [00:24<00:00, 416.14images/s, loss=0.258] \n",
            "Epoch 3 Batch 156: 100%|| 10000/10000 [00:24<00:00, 405.42images/s, loss=0.0472] \n",
            "Epoch 4 Batch 156: 100%|| 10000/10000 [00:23<00:00, 431.76images/s, loss=0.0254]\n",
            "Epoch 5 Batch 156: 100%|| 10000/10000 [00:24<00:00, 416.06images/s, loss=0.0143] \n",
            "Epoch 6 Batch 156: 100%|| 10000/10000 [00:25<00:00, 395.01images/s, loss=0.0869]\n",
            "Epoch 7 Batch 156: 100%|| 10000/10000 [00:25<00:00, 398.54images/s, loss=0.0251] \n",
            "Epoch 8 Batch 156: 100%|| 10000/10000 [00:25<00:00, 392.48images/s, loss=0.042]  \n",
            "Epoch 9 Batch 156: 100%|| 10000/10000 [00:24<00:00, 400.99images/s, loss=0.0436] \n",
            "Epoch 10 Batch 156: 100%|| 10000/10000 [00:25<00:00, 397.92images/s, loss=0.0243]  \n",
            "Epoch 11 Batch 156: 100%|| 10000/10000 [00:23<00:00, 422.01images/s, loss=0.000798]\n",
            "Epoch 12 Batch 156: 100%|| 10000/10000 [00:23<00:00, 422.08images/s, loss=0.947]   \n",
            "Epoch 13 Batch 156: 100%|| 10000/10000 [00:24<00:00, 413.74images/s, loss=0.852]  \n",
            "Epoch 14 Batch 156: 100%|| 10000/10000 [00:25<00:00, 399.80images/s, loss=0.0324]  \n",
            "Epoch 15 Batch 156: 100%|| 10000/10000 [00:24<00:00, 405.37images/s, loss=0.0294]  \n",
            "Epoch 16 Batch 156: 100%|| 10000/10000 [00:24<00:00, 406.56images/s, loss=0.00017] \n",
            "Epoch 17 Batch 156: 100%|| 10000/10000 [00:22<00:00, 438.55images/s, loss=0.000591]\n",
            "Epoch 18 Batch 156: 100%|| 10000/10000 [00:23<00:00, 421.28images/s, loss=0.0162]  \n",
            "Epoch 19 Batch 156: 100%|| 10000/10000 [00:23<00:00, 417.86images/s, loss=5.72e-5] \n",
            "Epoch 20 Batch 156: 100%|| 10000/10000 [00:24<00:00, 412.40images/s, loss=5.45e-5] \n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "312f7b6600164d93b62b016272f00039",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_on_current_task_only</td><td></td></tr><tr><td>average_accuracy</td><td></td></tr><tr><td>forgetting_measure</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>lr</td><td></td></tr><tr><td>test_accucracy</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_on_current_task_only</td><td>97.45</td></tr><tr><td>average_accuracy</td><td>19.49</td></tr><tr><td>forgetting_measure</td><td>95.4375</td></tr><tr><td>loss</td><td>5e-05</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accucracy</td><td>97.45</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">2024_04_07_08_55_18</strong> at: <a href='https://wandb.ai/fabianfuchs/continual_learning/runs/f8yhw0dv/workspace' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning/runs/f8yhw0dv/workspace</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 26 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240407_105518-f8yhw0dv\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for model in models:\n",
        "    train_tasks_sequentially(\n",
        "        model_dict=deepcopy(model),\n",
        "        device=device,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        tasks=tasks,\n",
        "        lr=lr,\n",
        "        weight_decay=weight_decay,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential with rehearsal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "x4krDh2uGeqT"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'constructor'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[30], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m memory_size_per_task \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m2000\u001b[39m, \u001b[38;5;241m5000\u001b[39m, \u001b[38;5;241m10000\u001b[39m]:\n\u001b[1;32m----> 3\u001b[0m         \u001b[43mtrain_tasks_sequentially_rehearsal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmemory_size_per_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_size_per_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[14], line 14\u001b[0m, in \u001b[0;36mtrain_tasks_sequentially_rehearsal\u001b[1;34m(model_dict, device, epochs, batch_size, tasks, lr, weight_decay, memory_size_per_task, criterion, scheduler)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_tasks_sequentially_rehearsal\u001b[39m(  \u001b[38;5;66;03m# noqa: PLR0913\u001b[39;00m\n\u001b[0;32m      2\u001b[0m     model_dict: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m      3\u001b[0m     device: torch\u001b[38;5;241m.\u001b[39mdevice,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# build model\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     constructor \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstructor\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m model_dict\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m     model \u001b[38;5;241m=\u001b[39m constructor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_dict)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'constructor'"
          ]
        }
      ],
      "source": [
        "for model in models:\n",
        "    for memory_size_per_task in [1000, 2000, 5000, 10000]:\n",
        "        train_tasks_sequentially_rehearsal(\n",
        "            model_dict=model,\n",
        "            device=device,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            tasks=tasks,\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay,\n",
        "            memory_size_per_task=memory_size_per_task,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential with elastic weight consolidation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for model in models:\n",
        "    for ewc_lambda in [0.2, 0.4, 0.6]:\n",
        "        train_tasks_sequentially_elastic_weight_consolidation(\n",
        "            model_dict=model,\n",
        "            device=device,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            tasks=tasks,\n",
        "            lr=lr,\n",
        "            weight_decay=weight_decay,\n",
        "            ewc_lambda=ewc_lambda,\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
