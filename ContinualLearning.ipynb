{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIEher0OlQ61",
        "outputId": "646021aa-964a-4b61-d5ee-5345a2995b79"
      },
      "outputs": [],
      "source": [
        "#!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "zJ7xNU3NcCwz",
        "outputId": "b33e221c-3287-4505-8379-f35213824cf1"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from copy import deepcopy\n",
        "from datetime import datetime, timezone\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import ConcatDataset, DataLoader, Dataset, Subset\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zk95CyQP6Sfa"
      },
      "source": [
        "## Weights and Bias Login\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Amah_vX1lNE-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "wandb: Currently logged in as: fabianfuchs. Use `wandb login --relogin` to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7odmCw657Me2"
      },
      "source": [
        "## Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ConvNeXtV2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL0UcU1cGeqP"
      },
      "source": [
        "Got source code for the ConvNeXtV2 model from https://github.com/facebookresearch/ConvNeXt-V2/blob/main/models/convnextv2.py and removed drop path and custom weight initialization. Added variable patch size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kA6kljA77MAe"
      },
      "outputs": [],
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"\"\"LayerNorm that supports two data formats: channels_last (default) or channels_first.\n",
        "    The ordering of the dimensions in the inputs. channels_last corresponds to inputs with\n",
        "    shape (batch_size, height, width, channels) while channels_first corresponds to inputs\n",
        "    with shape (batch_size, channels, height, width).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
        "        super().__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(normalized_shape))\n",
        "        self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
        "        self.eps = eps\n",
        "        self.data_format = data_format\n",
        "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
        "            raise NotImplementedError\n",
        "        self.normalized_shape = (normalized_shape,)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.data_format == \"channels_last\":\n",
        "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
        "        elif self.data_format == \"channels_first\":\n",
        "            u = x.mean(1, keepdim=True)\n",
        "            s = (x - u).pow(2).mean(1, keepdim=True)\n",
        "            x = (x - u) / torch.sqrt(s + self.eps)\n",
        "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
        "            return x\n",
        "\n",
        "\n",
        "class GRN(nn.Module):\n",
        "    \"\"\"GRN (Global Response Normalization) layer\"\"\"\n",
        "\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.gamma = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
        "        self.beta = nn.Parameter(torch.zeros(1, 1, 1, dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        Gx = torch.norm(x, p=2, dim=(1, 2), keepdim=True)\n",
        "        Nx = Gx / (Gx.mean(dim=-1, keepdim=True) + 1e-6)\n",
        "        return self.gamma * (x * Nx) + self.beta + x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"ConvNeXtV2 Block.\"\"\"\n",
        "\n",
        "    def __init__(self, dim, drop_path=0.0):\n",
        "        \"\"\"ConvNeXtV2 Block.\n",
        "\n",
        "        Args:\n",
        "            dim (int): Number of input channels.\n",
        "            drop_path (float): Stochastic depth rate. Default: 0.0\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=7, padding=3, groups=dim)  # depthwise conv\n",
        "        self.norm = LayerNorm(dim, eps=1e-6)\n",
        "        self.pwconv1 = nn.Linear(dim, 4 * dim)  # pointwise/1x1 convs, implemented with linear layers\n",
        "        self.act = nn.GELU()\n",
        "        self.grn = GRN(4 * dim)\n",
        "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        input = x\n",
        "        x = self.dwconv(x)\n",
        "        x = x.permute(0, 2, 3, 1)  # (N, C, H, W) -> (N, H, W, C)\n",
        "        x = self.norm(x)\n",
        "        x = self.pwconv1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.grn(x)\n",
        "        x = self.pwconv2(x)\n",
        "        x = x.permute(0, 3, 1, 2)  # (N, H, W, C) -> (N, C, H, W)\n",
        "\n",
        "        return input + x\n",
        "\n",
        "\n",
        "class ConvNeXtV2(nn.Module):\n",
        "    \"\"\"ConvNeXt V2.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_chans=3,\n",
        "        num_classes=1000,\n",
        "        depths=[3, 3, 9, 3],\n",
        "        dims=[96, 192, 384, 768],\n",
        "        drop_path_rate=0.0,\n",
        "        patch_size=1,\n",
        "    ):\n",
        "        \"\"\"ConvNeXt V2.\n",
        "\n",
        "        Args:\n",
        "            in_chans (int): Number of input image channels. Default: 3\n",
        "            num_classes (int): Number of classes for classification head. Default: 1000\n",
        "            depths (tuple(int)): Number of blocks at each stage. Default: [3, 3, 9, 3]\n",
        "            dims (int): Feature dimension at each stage. Default: [96, 192, 384, 768]\n",
        "            drop_path_rate (float): Stochastic depth rate. Default: 0.\n",
        "            head_init_scale (float): Init scaling value for classifier weights and biases. Default: 1.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.depths = depths\n",
        "        self.downsample_layers = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
        "        stem = nn.Sequential(\n",
        "            nn.Conv2d(in_chans, dims[0], kernel_size=patch_size, stride=patch_size),\n",
        "            LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\"),\n",
        "        )\n",
        "        self.downsample_layers.append(stem)\n",
        "        for i in range(3):\n",
        "            downsample_layer = nn.Sequential(\n",
        "                LayerNorm(dims[i], eps=1e-6, data_format=\"channels_first\"),\n",
        "                nn.Conv2d(dims[i], dims[i + 1], kernel_size=2, stride=2),\n",
        "            )\n",
        "            self.downsample_layers.append(downsample_layer)\n",
        "\n",
        "        self.stages = nn.ModuleList()  # 4 feature resolution stages, each consisting of multiple residual blocks\n",
        "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
        "        cur = 0\n",
        "        for i in range(4):\n",
        "            stage = nn.Sequential(*[Block(dim=dims[i], drop_path=dp_rates[cur + j]) for j in range(depths[i])])\n",
        "            self.stages.append(stage)\n",
        "            cur += depths[i]\n",
        "\n",
        "        self.norm = nn.LayerNorm(dims[-1], eps=1e-6)  # final norm layer\n",
        "        self.head = nn.Linear(dims[-1], num_classes)\n",
        "\n",
        "    def forward_features(self, x):\n",
        "        for i in range(4):\n",
        "            x = self.downsample_layers[i](x)\n",
        "            x = self.stages[i](x)\n",
        "        return self.norm(x.mean([-2, -1]))  # global average pooling, (N, C, H, W) -> (N, C)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.forward_features(x)\n",
        "        x = self.head(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ConvMixer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "source code from here https://github.com/kentaroy47/vision-transformers-cifar10/blob/main/README.md\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.fn(x) + x\n",
        "\n",
        "\n",
        "def ConvMixer(dim, depth, kernel_size=9, patch_size=7, n_classes=1000):\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(3, dim, kernel_size=patch_size, stride=patch_size),\n",
        "        nn.GELU(),\n",
        "        nn.BatchNorm2d(dim),\n",
        "        *[\n",
        "            nn.Sequential(\n",
        "                Residual(\n",
        "                    nn.Sequential(\n",
        "                        nn.Conv2d(dim, dim, kernel_size, groups=dim, padding=\"same\"), nn.GELU(), nn.BatchNorm2d(dim)\n",
        "                    )\n",
        "                ),\n",
        "                nn.Conv2d(dim, dim, kernel_size=1),\n",
        "                nn.GELU(),\n",
        "                nn.BatchNorm2d(dim),\n",
        "            )\n",
        "            for i in range(depth)\n",
        "        ],\n",
        "        nn.AdaptiveAvgPool2d((1, 1)),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(dim, n_classes),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS1TSvMr6VrH"
      },
      "source": [
        "## Functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QNKuM6tj6Q7q"
      },
      "outputs": [],
      "source": [
        "def get_classes() -> tuple:\n",
        "    \"\"\"Return class labels of CIFAR-10 dataset.\"\"\"\n",
        "    return (\"plane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
        "\n",
        "\n",
        "def get_datasets(tasks: int) -> tuple[list[Subset], list[Subset]]:\n",
        "    \"\"\"Split CIFAR-10 dataset into task specific subsets.\n",
        "\n",
        "    Args:\n",
        "        tasks (int): Number of tasks to split the dataset into.\n",
        "\n",
        "    Returns:\n",
        "        tuple[list[Subset], list[Subset]]: Tuple containing two list with the train and test subsets.\n",
        "    \"\"\"\n",
        "    classes = get_classes()\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n",
        "    classes_per_task = torch.linspace(0, len(classes), tasks + 1, dtype=torch.int)\n",
        "    trainsets = []\n",
        "    testsets = []\n",
        "    train_targets = torch.tensor(trainset.targets)\n",
        "    test_targets = torch.tensor(testset.targets)\n",
        "    for i in range(len(classes_per_task) - 1):\n",
        "        train_indices = []\n",
        "        test_indices = []\n",
        "        for j in range(classes_per_task[i], classes_per_task[i + 1]):\n",
        "            train_indices.extend((train_targets == j).nonzero(as_tuple=False).flatten().tolist())\n",
        "            test_indices.extend((test_targets == j).nonzero(as_tuple=False).flatten().tolist())\n",
        "        trainsets.append(Subset(trainset, train_indices))\n",
        "        testsets.append(Subset(testset, test_indices))\n",
        "    return trainsets, testsets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8E3w1c8iGeqQ"
      },
      "outputs": [],
      "source": [
        "def accuracy(testset: Dataset, model: nn.Module, device: torch.device, batch_size=1) -> float:\n",
        "    testloader = DataLoader(testset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for images, labels in testloader:\n",
        "        # calculate outputs by running images through the network\n",
        "        predictions = model(images.to(device=device))\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = torch.max(predictions.data, 1)\n",
        "        correct += (predicted == labels.to(device=device)).sum().item()\n",
        "    return 100 * correct / len(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nDcsV9XUGeqR"
      },
      "outputs": [],
      "source": [
        "def average_accuracy(\n",
        "    testsets: list[Dataset],\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    return_intermediate: bool = False,  # noqa: FBT001, FBT002\n",
        ") -> float | tuple[float, list[float]]:\n",
        "    average_accuracy = 0\n",
        "    average_accuracies = []\n",
        "    for i in range(len(testsets)):\n",
        "        task_accuracy = accuracy(testset=testsets[i], model=model, device=device)\n",
        "        average_accuracy += task_accuracy\n",
        "        average_accuracies.append(task_accuracy)\n",
        "    if return_intermediate:\n",
        "        return average_accuracy / len(testsets), average_accuracies\n",
        "    return average_accuracy / len(testsets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forgetting_measure(average_accuracies_per_training_per_task: list[list[float]], current_task: int) -> float:\n",
        "    forgetting_measure = 0\n",
        "    for j in range(current_task):  # exclude current task\n",
        "        f = 0\n",
        "        for i in range(j, current_task):  # exclude current task\n",
        "            f_ = (\n",
        "                average_accuracies_per_training_per_task[i][j]\n",
        "                - average_accuracies_per_training_per_task[current_task][j]\n",
        "            )\n",
        "            if f_ > f:\n",
        "                f = f_\n",
        "        forgetting_measure += f\n",
        "    return forgetting_measure / current_task\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.66666666666667"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "average_accuracies_per_training_per_task = [[100], [50, 100], [25, 50, 100], [25, 25, 50, 100]]\n",
        "forgetting_measure(average_accuracies_per_training_per_task=average_accuracies_per_training_per_task, current_task=3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### train loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IbR9W9Tw7AVI"
      },
      "outputs": [],
      "source": [
        "def train_on_task(\n",
        "    trainset: Dataset,\n",
        "    testset: Dataset,\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        "):\n",
        "    # create dataloaders\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    # move model to device\n",
        "    model.to(device=device)\n",
        "\n",
        "    if criterion is None:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    if scheduler is None:\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer,\n",
        "            max_lr=lr,\n",
        "            steps_per_epoch=len(trainloader),\n",
        "            epochs=epochs,\n",
        "        )\n",
        "\n",
        "    # training\n",
        "    for epoch in range(epochs):\n",
        "        # train one epoch\n",
        "        with tqdm(total=len(trainset), unit=\"images\") as progress_bar:\n",
        "            model.train()\n",
        "            for i, (images, labels) in enumerate(trainloader):\n",
        "                progress_bar.set_description(f\"Epoch {epoch+1} Batch {i}\")\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                prediction = model(images.to(device=device))\n",
        "                # calc loss\n",
        "                loss = criterion(prediction, labels.to(device=device))\n",
        "                # backward\n",
        "                loss.backward()\n",
        "                # optimizer\n",
        "                optimizer.step()\n",
        "                # scheduler\n",
        "                scheduler.step()\n",
        "                progress_bar.set_postfix(loss=loss.item())\n",
        "                progress_bar.update(labels.shape[0])\n",
        "                wandb.log({\"loss\": loss})\n",
        "                wandb.log({\"lr\": scheduler.get_last_lr()[0]})\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model{epoch}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "        # eval\n",
        "        test_accucracy = accuracy(testset=testset, model=model, device=device, batch_size=batch_size)\n",
        "        wandb.log({\"test_accucracy\": test_accucracy})\n",
        "\n",
        "    # save final model\n",
        "    path = Path(wandb.run.dir).joinpath(\"model.pth\")\n",
        "    torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### concurrent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_tasks_concurrently(  # noqa: PLR0913\n",
        "    model_dict: dict,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        ") -> None:\n",
        "    # build model\n",
        "    constructor = model_dict.pop(\"constructor\")\n",
        "    model_name = model_dict.pop(\"name\")\n",
        "    model = constructor(*model_dict)\n",
        "\n",
        "    # setup logging\n",
        "    project_name = \"continual_learning\"\n",
        "    run_name = f\"{datetime.now(tz=timezone.utc).strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "    config = {\n",
        "        \"training_method\": \"concurrently\",\n",
        "        \"model_name\": model_name,\n",
        "        \"dataset\": \"CIFAR-10\",\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"lr\": lr,\n",
        "        \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "    }\n",
        "    config.update(model_dict)\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config=config,\n",
        "    )\n",
        "\n",
        "    # get datasets\n",
        "    trainsets, testsets = get_datasets(tasks=1)\n",
        "\n",
        "    train_on_task(\n",
        "        trainset=trainsets[0],\n",
        "        testset=testsets[0],\n",
        "        model=model,\n",
        "        device=device,\n",
        "        optimizer=optimizer,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        lr=lr,\n",
        "        criterion=criterion,\n",
        "        scheduler=scheduler,\n",
        "    )\n",
        "    # finish logging run\n",
        "    wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### sequentially\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gQIXFn8FGeqR"
      },
      "outputs": [],
      "source": [
        "def train_tasks_sequentially(  # noqa: PLR0913\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    tasks: int,\n",
        "    lr: float,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        ") -> None:\n",
        "    # setup logging\n",
        "    project_name = \"continual_learning\"\n",
        "    run_name = f\"{datetime.now(tz=timezone.utc).strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config={\n",
        "            \"training_method\": \"sequentially\",\n",
        "            \"dataset\": \"CIFAR-10\",\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"tasks\": tasks,\n",
        "            \"lr\": lr,\n",
        "            \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # get datasets\n",
        "    trainsets, testsets = get_datasets(tasks=tasks)\n",
        "\n",
        "    avg_accs_per_task = []\n",
        "    for k in range(tasks):\n",
        "        # train model on task\n",
        "        train_on_task(\n",
        "            trainset=trainsets[k],\n",
        "            testset=testsets[k],\n",
        "            model=model,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "        )\n",
        "        # evaluate model\n",
        "        avg_acc, avg_accs = average_accuracy(\n",
        "            testsets=testsets[: k + 1],  # include current task\n",
        "            model=model,\n",
        "            device=device,\n",
        "            return_intermediate=True,\n",
        "        )\n",
        "        avg_accs_per_task.append(avg_accs)\n",
        "        wandb.log({\"accuracy_on_current_task_only\": avg_accs[-1]})\n",
        "        wandb.log({\"average_accuracy\": avg_acc})\n",
        "\n",
        "        # calculate forgetting measure as defined here https://arxiv.org/pdf/2302.00487.pdf\n",
        "        if k > 0:  # forgetting measure only makes sense, if we already trained on prior task\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"forgetting_measure\": forgetting_measure(\n",
        "                        average_accuracies_per_training_per_task=avg_accs_per_task,\n",
        "                        current_task=k,\n",
        "                    ),\n",
        "                },\n",
        "            )\n",
        "\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model_task{k}_of{tasks}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "    # finish logging run\n",
        "    wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqsnE1JcGeqS"
      },
      "source": [
        "check accuracy_on_current_task_only\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### rehearsal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_tasks_sequentially_rehearsal(  # noqa: PLR0913\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    tasks: int,\n",
        "    lr: float,\n",
        "    memory_size_per_task: int,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        ") -> None:\n",
        "    # setup logging\n",
        "    project_name = \"continual_learning\"\n",
        "    run_name = f\"{datetime.now(tz=timezone.utc).strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config={\n",
        "            \"training_method\": \"sequentially with rehearsal\",\n",
        "            \"dataset\": \"CIFAR-10\",\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"tasks\": tasks,\n",
        "            \"lr\": lr,\n",
        "            \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "            \"memory_size_per_task\": memory_size_per_task,\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # get datasets\n",
        "    trainsets, testsets = get_datasets(tasks=tasks)\n",
        "\n",
        "    avg_accs_per_task = []\n",
        "    memories = []\n",
        "    for k in range(tasks):\n",
        "        # train model on task\n",
        "        train_on_task(\n",
        "            trainset=ConcatDataset([trainsets[k], *memories]),\n",
        "            testset=testsets[k],\n",
        "            model=model,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "        )\n",
        "        # evaluate model\n",
        "        avg_acc, avg_accs = average_accuracy(\n",
        "            testsets=testsets[: k + 1],  # include current task\n",
        "            model=model,\n",
        "            device=device,\n",
        "            return_intermediate=True,\n",
        "        )\n",
        "        avg_accs_per_task.append(avg_accs)\n",
        "        wandb.log({\"accuracy_on_current_task_only\": avg_accs[-1]})\n",
        "        wandb.log({\"average_accuracy\": avg_acc})\n",
        "\n",
        "        # calculate forgetting measure as defined here https://arxiv.org/pdf/2302.00487.pdf\n",
        "        if k > 0:  # forgetting measure only makes sense, if we already trained on prior task\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"forgetting_measure\": forgetting_measure(\n",
        "                        average_accuracies_per_training_per_task=avg_accs_per_task,\n",
        "                        current_task=k,\n",
        "                    ),\n",
        "                },\n",
        "            )\n",
        "\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model_task{k}_of{tasks}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "        # add come images and labels from current task to memory\n",
        "        random_indices = torch.randint(low=0, high=len(trainsets[k - 1]), size=(memory_size_per_task,))\n",
        "        memory_task = Subset(trainsets[k], random_indices)\n",
        "        memories.append(memory_task)\n",
        "\n",
        "    # finish logging run\n",
        "    wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### elastic weight consolidation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_on_task_with_elastic_weight_loss(\n",
        "    trainset: Dataset,\n",
        "    testset: Dataset,\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    lr: float,\n",
        "    fisher_dict: dict,\n",
        "    optpar_dict: dict,\n",
        "    ewc_lambda: float,\n",
        "    current_task: int,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        "):\n",
        "    # create dataloaders\n",
        "    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "    # move model to device\n",
        "    model.to(device=device)\n",
        "\n",
        "    if criterion is None:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    if scheduler is None:\n",
        "        scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "            optimizer,\n",
        "            max_lr=lr,\n",
        "            steps_per_epoch=len(trainloader),\n",
        "            epochs=epochs,\n",
        "        )\n",
        "\n",
        "    # training\n",
        "    for epoch in range(epochs):\n",
        "        # train one epoch\n",
        "        with tqdm(total=len(trainset), unit=\"images\") as progress_bar:\n",
        "            model.train()\n",
        "            for i, (images, labels) in enumerate(trainloader):\n",
        "                progress_bar.set_description(f\"Epoch {epoch+1} Batch {i}\")\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                prediction = model(images.to(device=device))\n",
        "                # calc loss\n",
        "                loss = criterion(prediction, labels.to(device=device))\n",
        "\n",
        "                # add elastic weight loss\n",
        "                for task in range(current_task):\n",
        "                    for name, param in model.named_parameters():\n",
        "                        fisher = fisher_dict[task][name]\n",
        "                        optpar = optpar_dict[task][name]\n",
        "                        loss += (fisher * (optpar - param).pow(2)).sum() * ewc_lambda\n",
        "\n",
        "                # backward\n",
        "                loss.backward()\n",
        "                # optimizer\n",
        "                optimizer.step()\n",
        "                # scheduler\n",
        "                scheduler.step()\n",
        "                progress_bar.set_postfix(loss=loss.item())\n",
        "                progress_bar.update(labels.shape[0])\n",
        "                wandb.log({\"loss\": loss})\n",
        "                wandb.log({\"lr\": scheduler.get_last_lr()[0]})\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model{epoch}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "        # eval\n",
        "        test_accucracy = accuracy(testset=testset, model=model, device=device, batch_size=batch_size)\n",
        "        wandb.log({\"test_accucracy\": test_accucracy})\n",
        "\n",
        "    # save final model\n",
        "    path = Path(wandb.run.dir).joinpath(\"model.pth\")\n",
        "    torch.save(model.state_dict(), path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_tasks_sequentially_elastic_weight_consolidation(  # noqa: PLR0913\n",
        "    model: nn.Module,\n",
        "    device: torch.device,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    epochs: int,\n",
        "    batch_size: int,\n",
        "    tasks: int,\n",
        "    lr: float,\n",
        "    ewc_lambda: float,\n",
        "    criterion: nn.modules.loss._Loss | None = None,\n",
        "    scheduler: torch.optim.lr_scheduler.LRScheduler | None = None,\n",
        ") -> None:\n",
        "    # setup logging\n",
        "    project_name = \"continual_learning\"\n",
        "    run_name = f\"{datetime.now(tz=timezone.utc).strftime('%Y_%m_%d_%H_%M_%S')}\"\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config={\n",
        "            \"training_method\": \"sequentially with elastic weight consolidation\",\n",
        "            \"dataset\": \"CIFAR-10\",\n",
        "            \"epochs\": epochs,\n",
        "            \"batch_size\": batch_size,\n",
        "            \"tasks\": tasks,\n",
        "            \"lr\": lr,\n",
        "            \"num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "        },\n",
        "    )\n",
        "\n",
        "    # get datasets\n",
        "    trainsets, testsets = get_datasets(tasks=tasks)\n",
        "\n",
        "    avg_accs_per_task = []\n",
        "    fisher_dict = {}\n",
        "    optpar_dict = {}\n",
        "    for k in range(tasks):\n",
        "        train_on_task_with_elastic_weight_loss(\n",
        "            trainset=trainsets[k],\n",
        "            testset=testsets[k],\n",
        "            model=model,\n",
        "            device=device,\n",
        "            optimizer=optimizer,\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            fisher_dict=fisher_dict,\n",
        "            optpar_dict=optpar_dict,\n",
        "            ewc_lambda=ewc_lambda,\n",
        "            current_task=k,\n",
        "            criterion=criterion,\n",
        "            scheduler=scheduler,\n",
        "        )\n",
        "        # evaluate model\n",
        "        avg_acc, avg_accs = average_accuracy(\n",
        "            testsets=testsets[: k + 1],  # include current task\n",
        "            model=model,\n",
        "            device=device,\n",
        "            return_intermediate=True,\n",
        "        )\n",
        "        avg_accs_per_task.append(avg_accs)\n",
        "        wandb.log({\"accuracy_on_current_task_only\": avg_accs[-1]})\n",
        "        wandb.log({\"average_accuracy\": avg_acc})\n",
        "\n",
        "        # calculate forgetting measure as defined here https://arxiv.org/pdf/2302.00487.pdf\n",
        "        if k > 0:  # forgetting measure only makes sense, if we already trained on prior task\n",
        "            wandb.log(\n",
        "                {\n",
        "                    \"forgetting_measure\": forgetting_measure(\n",
        "                        average_accuracies_per_training_per_task=avg_accs_per_task,\n",
        "                        current_task=k,\n",
        "                    ),\n",
        "                },\n",
        "            )\n",
        "\n",
        "        # save model\n",
        "        path = Path(wandb.run.dir).joinpath(f\"model_task{k}_of{tasks}.pth\")\n",
        "        torch.save(model.state_dict(), path)\n",
        "\n",
        "        # gradients accumulated can be used to calculate fisher\n",
        "        fisher_dict[k] = {}\n",
        "        optpar_dict[k] = {}\n",
        "        for name, param in model.named_parameters():\n",
        "            optpar_dict[k][name] = param.data.clone()\n",
        "            fisher_dict[k][name] = param.grad.data.clone().pow(2)\n",
        "\n",
        "    # finish logging run\n",
        "    wandb.finish()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### wandb\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UILvQs6gGeqS"
      },
      "outputs": [],
      "source": [
        "def load_weights_from_wandb(model: nn.Module, run_name: str) -> nn.Module:\n",
        "    best_model = wandb.restore(\n",
        "        \"model.pth\",\n",
        "        run_path=f\"fabianfuchs/continual_learning/{run_name}\",\n",
        "        root=Path.cwd().joinpath(\"checkpoints\"),\n",
        "        replace=True,\n",
        "    )\n",
        "\n",
        "    # use the \"name\" attribute of the returned object if your framework expects a filename, e.g. as in Keras\n",
        "    model.load_state_dict(torch.load(best_model.name))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIt_EXa1GeqS"
      },
      "source": [
        "## Standard Setting\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3psLpC6hGeqS"
      },
      "outputs": [],
      "source": [
        "epochs = 1\n",
        "batch_size = 64\n",
        "lr = 0.01\n",
        "momentum = 0.9\n",
        "weight_decay = 0.01\n",
        "device = torch.device(\"cpu\")\n",
        "tasks = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "models = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "convnext_minimal = {\n",
        "    \"constructor\": ConvNeXtV2,\n",
        "    \"name\": \"ConvNeXtV2\",\n",
        "    \"in_chans\": 3,\n",
        "    \"num_classes\": 10,\n",
        "    \"depths\": [2, 2, 2, 2],\n",
        "    \"dims\": [128, 128, 128, 128],\n",
        "    \"patch_size\": 1,\n",
        "}\n",
        "models.append(convnext_minimal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmRL4K2LGeqS"
      },
      "outputs": [],
      "source": [
        "convnext_atto = {\n",
        "    \"constructor\": ConvNeXtV2,\n",
        "    \"name\": \"ConvNeXtV2\",\n",
        "    \"in_chans\": 3,\n",
        "    \"num_classes\": 10,\n",
        "    \"depths\": [2, 2, 6, 2],\n",
        "    \"dims\": [40, 80, 160, 320],\n",
        "    \"patch_size\": 1,\n",
        "}\n",
        "models.append(convnext_atto)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zX3B6pscGeqT"
      },
      "outputs": [],
      "source": [
        "convnext_tiny = {\n",
        "    \"constructor\": ConvNeXtV2,\n",
        "    \"name\": \"ConvNeXtV2\",\n",
        "    \"in_chans\": 3,\n",
        "    \"num_classes\": 10,\n",
        "    \"depths\": [3, 3, 9, 3],\n",
        "    \"dims\": [96, 192, 384, 768],\n",
        "    \"patch_size\": 1,\n",
        "}\n",
        "models.append(convnext_tiny)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "9OZ7CY4EGeqT"
      },
      "outputs": [],
      "source": [
        "convnext_tiny = {\n",
        "    \"constructor\": ConvNeXtV2,\n",
        "    \"name\": \"ConvNeXtV2\",\n",
        "    \"in_chans\": 3,\n",
        "    \"num_classes\": 10,\n",
        "    \"depths\": [3, 3, 27, 3],\n",
        "    \"dims\": [128, 256, 512, 1024],\n",
        "    \"patch_size\": 1,\n",
        "}\n",
        "models.append(convnext_tiny)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_mixer_minimal = {\n",
        "    \"constructor\": ConvMixer,\n",
        "    \"name\": \"ConvMixer\",\n",
        "    \"dim\": 128,\n",
        "    \"depth\": 4,\n",
        "    \"kernel_size\": 7,\n",
        "    \"patch_size\": 1,\n",
        "    \"n_classes\": 10,\n",
        "}\n",
        "models.append(conv_mixer_minimal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_mixer_atto = {\n",
        "    \"constructor\": ConvMixer,\n",
        "    \"name\": \"ConvMixer\",\n",
        "    \"dim\": 128,\n",
        "    \"depth\": 8,\n",
        "    \"kernel_size\": 7,\n",
        "    \"patch_size\": 1,\n",
        "    \"n_classes\": 10,\n",
        "}\n",
        "models.append(conv_mixer_atto)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_mixer_tiny = {\n",
        "    \"constructor\": ConvMixer,\n",
        "    \"name\": \"ConvMixer\",\n",
        "    \"dim\": 256,\n",
        "    \"depth\": 8,\n",
        "    \"kernel_size\": 7,\n",
        "    \"patch_size\": 1,\n",
        "    \"n_classes\": 10,\n",
        "}\n",
        "models.append(conv_mixer_tiny)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rHEyR98AGeqT"
      },
      "outputs": [],
      "source": [
        "for model in models:\n",
        "    # optimizer = optim.SGD(convnext.parameters(), lr=lr, momentum=momentum)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    train_tasks_concurrently(\n",
        "        model=model,\n",
        "        device=device,\n",
        "        optimizer=optimizer,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        lr=lr,\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R59sQDCoGeqT"
      },
      "source": [
        "## Sequential without modifications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "iwBNBJFzGeqT"
      },
      "outputs": [],
      "source": [
        "tasks = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0JqT_GCKNG3T"
      },
      "outputs": [],
      "source": [
        "# for model in models:\n",
        "#     # optimizer = optim.SGD(convnext.parameters(), lr=lr, momentum=momentum)\n",
        "#     optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#     train_tasks_sequentially(\n",
        "#         model=model,\n",
        "#         device=device,\n",
        "#         optimizer=optimizer,\n",
        "#         epochs=epochs,\n",
        "#         batch_size=batch_size,\n",
        "#         tasks=tasks,\n",
        "#         lr=lr,\n",
        "#     )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential with rehearsal\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "x4krDh2uGeqT"
      },
      "outputs": [],
      "source": [
        "# for model in models:\n",
        "#     for memory_size_per_task in [1000, 2000, 5000, 10000]:\n",
        "#         # optimizer = optim.SGD(convnext.parameters(), lr=lr, momentum=momentum)\n",
        "#         optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#         train_tasks_sequentially_rehearsal(\n",
        "#             model=model,\n",
        "#             device=device,\n",
        "#             optimizer=optimizer,\n",
        "#             epochs=epochs,\n",
        "#             batch_size=batch_size,\n",
        "#             tasks=tasks,\n",
        "#             lr=lr,\n",
        "#             memory_size_per_task=memory_size_per_task,\n",
        "#         )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sequential with elastic weight consolidation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\fabia\\Desktop\\ContinualLearning\\wandb\\run-20240406_192533-5zrwic0r</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fabianfuchs/continual_learning/runs/5zrwic0r' target=\"_blank\">2024_04_06_17_25_33</a></strong> to <a href='https://wandb.ai/fabianfuchs/continual_learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/fabianfuchs/continual_learning' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/fabianfuchs/continual_learning/runs/5zrwic0r' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning/runs/5zrwic0r</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 156: 100%|██████████| 10000/10000 [13:15<00:00, 12.57images/s, loss=0.311]\n",
            "Epoch 1 Batch 156: 100%|██████████| 10000/10000 [13:32<00:00, 12.31images/s, loss=0.695]\n",
            "Epoch 1 Batch 156: 100%|██████████| 10000/10000 [13:51<00:00, 12.03images/s, loss=0.696]\n",
            "Epoch 1 Batch 156: 100%|██████████| 10000/10000 [13:37<00:00, 12.24images/s, loss=0.724]\n",
            "Epoch 1 Batch 156: 100%|██████████| 10000/10000 [13:24<00:00, 12.43images/s, loss=0.738]\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8ae48104e6540a2a8b228ce0da9e506",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy_on_current_task_only</td><td>█▁▁▁▁</td></tr><tr><td>average_accuracy</td><td>█▂▂▁▁</td></tr><tr><td>forgetting_measure</td><td>█▃▂▁</td></tr><tr><td>loss</td><td>▁▁▁▁▁▁▁▁█▁▁▁▁▁▁▁█▁▁▁▁▁▁▁▅▁▁▁▁▁▁▁▇▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▂▅██▆▄▃▁▁▆█▇▆▄▂▁▂▆█▇▆▄▂▁▂▇█▇▆▃▂▁▂▇█▇▅▃▂▁</td></tr><tr><td>test_accucracy</td><td>█▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy_on_current_task_only</td><td>50.0</td></tr><tr><td>average_accuracy</td><td>10.0</td></tr><tr><td>forgetting_measure</td><td>58.2375</td></tr><tr><td>loss</td><td>0.73792</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>test_accucracy</td><td>50.0</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">2024_04_06_17_25_33</strong> at: <a href='https://wandb.ai/fabianfuchs/continual_learning/runs/5zrwic0r' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning/runs/5zrwic0r</a><br/> View project at: <a href='https://wandb.ai/fabianfuchs/continual_learning' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 7 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20240406_192533-5zrwic0r\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\fabia\\Desktop\\ContinualLearning\\wandb\\run-20240406_205027-yacahw15</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/fabianfuchs/continual_learning/runs/yacahw15' target=\"_blank\">2024_04_06_18_50_27</a></strong> to <a href='https://wandb.ai/fabianfuchs/continual_learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/fabianfuchs/continual_learning' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/fabianfuchs/continual_learning/runs/yacahw15' target=\"_blank\">https://wandb.ai/fabianfuchs/continual_learning/runs/yacahw15</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 61:  39%|███▉      | 3904/10000 [05:13<08:09, 12.46images/s, loss=0.686]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ewc_lambda \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.6\u001b[39m]:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# optimizer = optim.SGD(convnext.parameters(), lr=lr, momentum=momentum)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, weight_decay\u001b[38;5;241m=\u001b[39mweight_decay)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrain_tasks_sequentially_elastic_weight_consolidation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtasks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mewc_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mewc_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[16], line 37\u001b[0m, in \u001b[0;36mtrain_tasks_sequentially_elastic_weight_consolidation\u001b[1;34m(model, device, optimizer, epochs, batch_size, tasks, lr, ewc_lambda, criterion, scheduler)\u001b[0m\n\u001b[0;32m     35\u001b[0m optpar_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(tasks):\n\u001b[1;32m---> 37\u001b[0m     \u001b[43mtrain_on_task_with_elastic_weight_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainsets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtestset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtestsets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfisher_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfisher_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptpar_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptpar_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mewc_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mewc_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcurrent_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;66;03m# evaluate model\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     avg_acc, avg_accs \u001b[38;5;241m=\u001b[39m average_accuracy(\n\u001b[0;32m     55\u001b[0m         testsets\u001b[38;5;241m=\u001b[39mtestsets[: k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m],  \u001b[38;5;66;03m# include current task\u001b[39;00m\n\u001b[0;32m     56\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     57\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     58\u001b[0m         return_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     59\u001b[0m     )\n",
            "Cell \u001b[1;32mIn[15], line 56\u001b[0m, in \u001b[0;36mtrain_on_task_with_elastic_weight_loss\u001b[1;34m(trainset, testset, model, device, optimizer, epochs, batch_size, lr, fisher_dict, optpar_dict, ewc_lambda, current_task, criterion, scheduler)\u001b[0m\n\u001b[0;32m     53\u001b[0m         loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (fisher \u001b[38;5;241m*\u001b[39m (optpar \u001b[38;5;241m-\u001b[39m param)\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m*\u001b[39m ewc_lambda\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# backward\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# optimizer\u001b[39;00m\n\u001b[0;32m     58\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
            "File \u001b[1;32mc:\\Users\\fabia\\micromamba\\envs\\continual_learning\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\fabia\\micromamba\\envs\\continual_learning\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# for model in models:\n",
        "#     for ewc_lambda in [0.2, 0.4, 0.6]:\n",
        "#         # optimizer = optim.SGD(convnext.parameters(), lr=lr, momentum=momentum)\n",
        "#         optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "#         train_tasks_sequentially_elastic_weight_consolidation(\n",
        "#             model=model,\n",
        "#             device=device,\n",
        "#             optimizer=optimizer,\n",
        "#             epochs=epochs,\n",
        "#             batch_size=batch_size,\n",
        "#             tasks=tasks,\n",
        "#             lr=lr,\n",
        "#             ewc_lambda=ewc_lambda,\n",
        "#         )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
